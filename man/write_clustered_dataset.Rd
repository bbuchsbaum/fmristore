% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/read_write_hdf5.R
\name{write_clustered_dataset}
\alias{write_clustered_dataset}
\title{Write a clustered time series dataset to an HDF5 file}
\usage{
write_clustered_dataset(
  file,
  vecs,
  scan_names,
  mask,
  clusters,
  scan_metadata,
  cluster_metadata = NULL,
  compression = 4,
  chunk_size = 1024
)
}
\arguments{
\item{file}{An \code{\link[hdf5r]{H5File}} object or a character path to create a new file}

\item{vecs}{A list of \code{\link[neuroim2]{NeuroVec}} objects, one for each scan/run}

\item{scan_names}{Character vector of scan names corresponding to vecs}

\item{mask}{A \code{\link[neuroim2]{LogicalNeuroVol}} object defining the brain mask}

\item{clusters}{A \code{\link[neuroim2]{ClusteredNeuroVol}} object defining the cluster assignments}

\item{scan_metadata}{A list of lists containing metadata for each scan. Each inner list should contain:
\itemize{
  \item subject_id: Subject identifier
  \item task: Task name
  \item TR: Repetition time
  \item session: Session identifier
  \item ...: Additional metadata fields
}}

\item{cluster_metadata}{Optional data.frame or list containing cluster-level metadata with columns/elements:
\itemize{
  \item cluster_id: Cluster identifier
  \item description: Cluster description
  \item ...: Additional metadata fields
}}

\item{compression}{Compression level (0-9) for the data}

\item{chunk_size}{Size of chunks for HDF5 dataset storage}
}
\value{
The \code{\link[hdf5r]{H5File}} object
}
\description{
Write a clustered time series dataset to an HDF5 file
}
